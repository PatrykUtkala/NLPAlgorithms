{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPe9I0inH6W4PkvNhT/Wig",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PatrykUtkala/NLPAlgorithms/blob/main/FastTextUsage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "!pip install fasttext\n",
        "import fasttext.util\n",
        "import numpy as np\n",
        "import itertools\n",
        "from scipy.spatial.distance import cosine\n",
        "from scipy.spatial.distance import euclidean\n",
        "ft = fasttext.load_model(r'/content/gdrive/MyDrive/Fasttext/cc.pl.300.bin')\n",
        "# fasttext.util.reduce_model(ft, 100)\n",
        "\n",
        "print(ft.get_dimension())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XvgemRmsLDH",
        "outputId": "353177f6-983b-47fa-83a7-1bc218bbf251"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.10.0-py3-none-any.whl (213 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.21.6)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3163134 sha256=4ab482e63001383f38b148138dfa46eaad97f3aa0c54953c2a5a010fde2be96f\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.pl.300.bin.gz\n",
        "!gzip -d cc.pl.300.bin.gz\n",
        "import fasttext.util\n",
        "import numpy as np\n",
        "import itertools\n",
        "from scipy.spatial.distance import cosine\n",
        "from scipy.spatial.distance import euclidean\n",
        "ft = fasttext.load_model(r'cc.pl.300.bin')\n",
        "\n",
        "print(ft.get_dimension())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwgWo4Uutsqn",
        "outputId": "0e42fd4a-4991-4a5d-8c4a-7fb7b7652736"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.10.0-py3-none-any.whl (213 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.21.6)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3163177 sha256=f3ecf0f3a0e52b30024797e53c133fb07fa33be6e3172f6b234d89768b0b347c\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.10.0\n",
            "--2022-09-12 07:49:01--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.pl.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4503081312 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.pl.300.bin.gz’\n",
            "\n",
            "cc.pl.300.bin.gz    100%[===================>]   4.19G  47.4MB/s    in 96s     \n",
            "\n",
            "2022-09-12 07:50:38 (44.7 MB/s) - ‘cc.pl.300.bin.gz’ saved [4503081312/4503081312]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1-kKojIt1zKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Test\n",
        "word = 'Paryż'\n",
        "to_remember = 100\n",
        "tal = ft.get_word_vector(\"wampir\")\n",
        "fok = ft.get_word_vector('Paryż')\n",
        "point = (tal + fok)/2\n",
        "print(euclidean(point, fok), euclidean(point, tal))\n",
        "for i in range(20):\n",
        "  print(\"nowy:\", word)\n",
        "  a = ft.get_nearest_neighbors(word, k=200000)\n",
        "  for aa in a:\n",
        "    if ('Paryż' in aa[1]) or (\"wampir\" in aa[1]):\n",
        "      continue\n",
        "    fok = ft.get_word_vector(aa[1])\n",
        "    # result = np.sqrt(np.sum((tal - fok)**2))\n",
        "    result = euclidean(point, fok)\n",
        "    # print(result, aa[1])\n",
        "    if result < to_remember:\n",
        "      to_remember = result\n",
        "      word = aa[1]\n",
        "      # print(word, to_remember, np.sqrt(np.sum((fok - ft.get_word_vector('Paryż'))**2)))\n",
        "      print(word, to_remember,euclidean(ft.get_word_vector(word), ft.get_word_vector('Paryż')))"
      ],
      "metadata": {
        "id": "2xwZm2PIx4Rs",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['Paryż', 'kura', 'pióra', 'trawnik']\n",
        "points = [ft.get_word_vector(x) for x in words]\n",
        "target = np.sum(points, axis=0)/2\n",
        "word = words[0]\n",
        "to_remember = 100\n",
        "for i in range(5):\n",
        "  print(\"nowy:\", word)\n",
        "  a = ft.get_nearest_neighbors(word, k=200000)\n",
        "  for aa in a:\n",
        "    in_check = False\n",
        "    for w in words:\n",
        "      if w in aa[1]:\n",
        "        in_check=True\n",
        "    if in_check:\n",
        "      continue\n",
        "    fok = ft.get_word_vector(aa[1])\n",
        "    # result = np.sqrt(np.sum((tal - fok)**2))\n",
        "    result = euclidean(target, fok)\n",
        "    # print(result, aa[1])\n",
        "    if result < to_remember:\n",
        "      to_remember = result\n",
        "      word = aa[1]\n",
        "      # print(word, to_remember, np.sqrt(np.sum((fok - ft.get_word_vector('Paryż'))**2)))\n",
        "      print(word, to_remember)\n",
        "      for i, w in enumerate(words):\n",
        "        print(\"\\t\\t\", w, euclidean(fok, points[i]))\n",
        "\n",
        "print(\"result:\", word)\n"
      ],
      "metadata": {
        "id": "55KULKq7KU3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title defs\n",
        "def find_closest(words, number, embeddings):\n",
        "  if len(words)<number:\n",
        "    return words\n",
        "  b = np.array(list(itertools.combinations(words, number)))\n",
        "  l = []\n",
        "  for bb in b:\n",
        "    a = []\n",
        "    for words in bb:\n",
        "      a.append(embeddings[words])\n",
        "    a = np.array(a)\n",
        "    a = np.array(list(itertools.combinations(a, 2)))\n",
        "    l.append(np.sum(np.sqrt(np.sum(np.diff(a, axis=1)**2, axis=2))))\n",
        "  l = np.array(l)\n",
        "  return b[np.argmin(l)]\n",
        "\n",
        "\n",
        "def gen_word(words):\n",
        "  points = [ft.get_word_vector(x) for x in words]\n",
        "  target = np.sum(points, axis=0)/2\n",
        "  word = words[0]\n",
        "  to_remember = 100\n",
        "  for i in range(5):\n",
        "    print(\"nowy:\", word)\n",
        "    a = ft.get_nearest_neighbors(word, k=200000)\n",
        "    for aa in a:\n",
        "      in_check = False\n",
        "      for w in words:\n",
        "        if w in aa[1]:\n",
        "          in_check=True\n",
        "      if in_check:\n",
        "        continue\n",
        "      fok = ft.get_word_vector(aa[1])\n",
        "      # result = np.sqrt(np.sum((tal - fok)**2))\n",
        "      result = cosine(target, fok)\n",
        "      # print(result, aa[1])\n",
        "      if result < to_remember:\n",
        "        to_remember = result\n",
        "        word = aa[1]\n",
        "        # print(word, to_remember, np.sqrt(np.sum((fok - ft.get_word_vector('Paryż'))**2)))\n",
        "        print(word, to_remember)\n",
        "        for i, w in enumerate(words):\n",
        "          print(\"\\t\\t\", w, cosine(fok, points[i]))\n",
        "\n",
        "  return(word)\n",
        "\n",
        "def gen_word_av(words, avoided_words, embs, point):\n",
        "  points = [embs[x] for x in words]\n",
        "  target = ft.get_word_vector(point)\n",
        "  similarity = [cosine(target, x) for x in points]\n",
        "  sim_max = np.max(similarity)\n",
        "\n",
        "  anti_similarity = np.array([cosine(target, embs[x]) for x in avoided_words])\n",
        "  print('test', sim_max, \"word:\", point)\n",
        "  print(words)\n",
        "  print(similarity)\n",
        "  print(avoided_words)\n",
        "  print(anti_similarity)\n",
        "  print(anti_similarity < sim_max)\n",
        "  \n",
        "  \n"
      ],
      "metadata": {
        "id": "TrUToQ5jZiWt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Api"
      ],
      "metadata": {
        "id": "tj_zOcrJ2plt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi nest-asyncio pyngrok uvicorn\n",
        "\n",
        "from fastapi import FastAPI\n",
        "from fastapi.encoders import jsonable_encoder\n",
        "from fastapi.responses import JSONResponse\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "from pydantic import BaseModel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAuMmtoKmJzW",
        "outputId": "5acc347e-fe81-449b-8b94-9164877fc773"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.83.0-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting nest-asyncio\n",
            "  Downloading nest_asyncio-1.5.5-py3-none-any.whl (5.2 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-5.1.0.tar.gz (745 kB)\n",
            "\u001b[K     |████████████████████████████████| 745 kB 9.9 MB/s \n",
            "\u001b[?25hCollecting uvicorn\n",
            "  Downloading uvicorn-0.18.3-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting starlette==0.19.1\n",
            "  Downloading starlette-0.19.1-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from fastapi) (1.9.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from starlette==0.19.1->fastapi) (4.1.1)\n",
            "Collecting anyio<5,>=3.4.0\n",
            "  Downloading anyio-3.6.1-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 10.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<5,>=3.4.0->starlette==0.19.1->fastapi) (2.10)\n",
            "Collecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (6.0)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn) (7.1.2)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=19007 sha256=7002e54ed85e6b42f4d229bbad6128963f935acb7c5a4535255d6c2391520f7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/e6/af/ccf6598ecefecd44104069371795cb9b3afbcd16987f6ccfb3\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: sniffio, anyio, starlette, h11, uvicorn, pyngrok, nest-asyncio, fastapi\n",
            "Successfully installed anyio-3.6.1 fastapi-0.83.0 h11-0.13.0 nest-asyncio-1.5.5 pyngrok-5.1.0 sniffio-1.3.0 starlette-0.19.1 uvicorn-0.18.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = FastAPI()\n",
        "\n",
        "class Map(BaseModel):\n",
        "    team: int\n",
        "    current_game_map: list\n",
        "    current_word_list: list\n",
        "\n",
        "class Words(BaseModel):\n",
        "    current_word_list: list\n",
        "    password: str\n",
        "\n",
        "@app.get('/index')\n",
        "async def home():\n",
        "  return \"Hello World\"\n",
        "\n",
        "@app.post('/words')\n",
        "async def home(my_map: Map):\n",
        "  team = my_map.team\n",
        "  my_words = []\n",
        "  bad_words = []\n",
        "  for i, t in enumerate(my_map.current_game_map):\n",
        "    if t == team:\n",
        "      my_words.append(my_map.current_word_list[i])\n",
        "    else:\n",
        "      if my_map.current_word_list[i] != '':\n",
        "        bad_words.append(my_map.current_word_list[i])\n",
        "  embeddings = {x: ft.get_word_vector(x) for x in my_map.current_word_list}\n",
        "  closest = find_closest(my_words, 3, embeddings)\n",
        "\n",
        "  \n",
        "  word = gen_word(closest)\n",
        "  gen_word_av(closest, bad_words, embeddings, word)\n",
        "  # word = \"cwel\"\n",
        "  json_compatible_item_data = jsonable_encoder({\"word\": word, \"number\": 3})\n",
        "  return JSONResponse(content=json_compatible_item_data)\n",
        "\n",
        "@app.post('/find')\n",
        "async def home(words: Words):\n",
        "  password_emb = ft.get_word_vector(words.password)\n",
        "  embeddings = [ft.get_word_vector(x) for x in words.current_word_list ]\n",
        "  lowest = 100\n",
        "  current = None\n",
        "  for i, emb in enumerate(embeddings):\n",
        "    if words.current_word_list[i] == '':\n",
        "      continue\n",
        "    result = cosine(password_emb, emb)\n",
        "    print(result, words.current_word_list[i])\n",
        "    if result < lowest:\n",
        "      lowest = result\n",
        "      current = i\n",
        "      # print(result, words.current_word_list[current])\n",
        "  print(\"result\", words.current_word_list[current])\n",
        "  json_compatible_item_data = jsonable_encoder({\"word\": words.current_word_list[current]})\n",
        "  return JSONResponse(content=json_compatible_item_data)\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evmFH49TnuHl",
        "outputId": "d76fd6a4-516a-47bb-be92-97db9ffec74d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: http://0001-35-243-170-205.ngrok.io\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [58]\n",
            "INFO:uvicorn.error:Started server process [58]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:uvicorn.error:Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:uvicorn.error:Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n",
            "INFO:uvicorn.error:Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nowy: kontrakt\n",
            "Kontrakt 0.5275134742259979\n",
            "\t\t kontrakt 0.2128610610961914\n",
            "\t\t antarktyka 0.9061001464724541\n",
            "\t\t limuzyna 0.9471961408853531\n",
            "umowa 0.48974525928497314\n",
            "\t\t kontrakt 0.47965115308761597\n",
            "\t\t antarktyka 0.729116827249527\n",
            "\t\t limuzyna 0.7679914683103561\n",
            "bulwarówka 0.4653586745262146\n",
            "\t\t kontrakt 0.767968162894249\n",
            "\t\t antarktyka 0.6403999924659729\n",
            "\t\t limuzyna 0.5320163071155548\n",
            "limuzyn 0.4168802499771118\n",
            "\t\t kontrakt 0.803046241402626\n",
            "\t\t antarktyka 0.8096096962690353\n",
            "\t\t limuzyna 0.3009796738624573\n",
            "limuzyne 0.4031030535697937\n",
            "\t\t kontrakt 0.8078867197036743\n",
            "\t\t antarktyka 0.7084585130214691\n",
            "\t\t limuzyna 0.34261471033096313\n",
            "nowy: limuzyne\n",
            "nowy: limuzyne\n",
            "nowy: limuzyne\n",
            "nowy: limuzyne\n",
            "test 0.8078867197036743 word: limuzyne\n",
            "['kontrakt' 'antarktyka' 'limuzyna']\n",
            "[0.8078867197036743, 0.7084585130214691, 0.34261471033096313]\n",
            "['napad', 'moskwa', 'szkło', 'soczewka', 'połączenie', 'ambulans', 'ława', 'przewodnik', 'korzenie', 'talia', 'życie', 'dusza', 'muszla', 'babka', 'żołnierz', 'szpieg']\n",
            "[0.86108151 0.79502933 0.87407348 0.75863278 0.94037791 0.74895957\n",
            " 0.8092925  0.92719071 0.87832355 0.81632181 0.89307182 0.77982342\n",
            " 0.83283012 0.77653557 0.90820245 0.8821043 ]\n",
            "[False  True False  True False  True False False False False False  True\n",
            " False  True False False]\n",
            "INFO:     2001:4070:13::220:33:0 - \"POST /words HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:uvicorn.error:Shutting down\n",
            "INFO:     Finished server process [58]\n",
            "INFO:uvicorn.error:Finished server process [58]\n"
          ]
        }
      ]
    }
  ]
}